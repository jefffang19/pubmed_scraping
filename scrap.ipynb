{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.10 64-bit ('work': conda)",
   "display_name": "Python 3.6.10 64-bit ('work': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a656c7a8fdc3ffdbdd0e7c6d6d79734af4937a66f98e4099476e2e386f28d1b4"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "source": [
    "# Define Target url"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pubmed url\n",
    "# search\n",
    "# https://pubmed.ncbi.nlm.nih.gov/?term={keyword}&page={page#}\n",
    "# article\n",
    "# https://pubmed.ncbi.nlm.nih.gov/32265149/\n",
    "base_url = 'https://pubmed.ncbi.nlm.nih.gov'\n",
    "search_url = 'https://pubmed.ncbi.nlm.nih.gov/?term='\n",
    "page_url = '&page='"
   ]
  },
  {
   "source": [
    "# define scraping tags"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article name in search page\n",
    "search_article_name_tag = 'a'\n",
    "search_article_name_class = 'docsum-title'\n",
    "\n",
    "# abstract\n",
    "abstract_tag = 'div'\n",
    "abstract_class = 'abstract-content selected'\n",
    "\n",
    "keyword = 'COVID-19'"
   ]
  },
  {
   "source": [
    "# define scraping range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap from page start_page_num to page to_page_num\n",
    "start_page_num = 101\n",
    "to_page_num = 1000\n",
    "\n",
    "# save paths\n",
    "fpath = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start scraping\n",
    "page = start_page_num\n",
    "\n",
    "for i in range(start_page_num,to_page_num+1):\n",
    "    rq = requests.get(search_url + keyword + page_url + str(i)) # get search page\n",
    "    soup = BeautifulSoup(rq.text, 'lxml')\n",
    "    articles = soup.find_all(search_article_name_tag, class_=search_article_name_class)\n",
    "\n",
    "    title = []\n",
    "    abstract = []\n",
    "    for i in articles:\n",
    "        title.append(i.text.strip()) # title\n",
    "        # get abstract page\n",
    "        rq = requests.get(base_url + i.get('href'))\n",
    "        time.sleep(0.1)\n",
    "        soup = BeautifulSoup(rq.text, 'lxml')\n",
    "        # get abstract tag\n",
    "        articles = soup.find_all(abstract_tag, class_='abstract-content selected')\n",
    "\n",
    "        # check if no abstract\n",
    "        if articles == []:\n",
    "            abstract.append('')\n",
    "            continue\n",
    "        \n",
    "        # get abstract raw text\n",
    "        for a in articles:\n",
    "            temp = a.text.split()\n",
    "            temp = ' '.join(temp)\n",
    "\n",
    "        abstract.append(temp)\n",
    "\n",
    "    # save as csv\n",
    "    d = {'title' : title, 'abstract' : abstract}\n",
    "    one_page_df = pd.DataFrame(d)\n",
    "    one_page_df.to_csv(fpath + str(page) + '.csv')\n",
    "\n",
    "    page += 1\n",
    "    \n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}